{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01c5dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=KqwMbOPil3yk2j1WY94TmH0gEAmf9f&access_type=offline&code_challenge=bFjS0QC40vVYV4KEwkTneuZiYDEHonshG7ErULmVLAE&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [/Users/ivanmkc/.config/gcloud/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"ivanmkc-test\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth application-default login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff477b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "\n",
      "Credentials saved to file: [/Users/ivanmkc/.config/gcloud/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"ivanmkc-test\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project ivanmkc-test\n",
    "! gcloud auth application-default set-quota-project ivanmkc-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4c5b9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[core]\n",
      "account = ivanmkc@google.com\n",
      "disable_usage_reporting = False\n",
      "project = ivanmkc-test\n",
      "[metrics]\n",
      "environment = cloudcode.vscode\n",
      "environment_version = 2.27.0\n",
      "[run]\n",
      "region = us-central1\n",
      "\n",
      "Your active configuration is: [default]\n"
     ]
    }
   ],
   "source": [
    "! gcloud config list\n",
    "# ! pip install google-cloud-aiplatform tenacity --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36a098c-3bd1-4c7a-95e7-7b73bd81a815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import abc\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Model(abc.ABC):\n",
    "    name: str\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def translate(self) -> str:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652237f7-e5ac-4815-8270-c4571fb818af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "\n",
    "import concurrent\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Constants\n",
    "max_tokens = 60\n",
    "max_tokens_description = 90\n",
    "temperature = 0.0\n",
    "top_p = 1.0\n",
    "top_k = 1\n",
    "raw_response = True\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "class VertexAIEndpointModel(Model):\n",
    "    def __init__(self, endpoint: str, location: str, target_language: str):\n",
    "        self.target_language = target_language\n",
    "        self.endpoint = aiplatform.Endpoint(endpoint, location=location)\n",
    "\n",
    "    @property\n",
    "    def system_instructions(self) -> str:\n",
    "        return f\"\"\"\n",
    "# Instruction\n",
    "Translate the following text to the target language. Only return the translated text and nothing else.\n",
    "\n",
    "# Target language: {self.target_language}\n",
    "\n",
    "# Format\n",
    "\n",
    "Text: <text_to_translate>\n",
    "Translation: <translated_text>\n",
    "\n",
    "# Translate the below text\n",
    "        \"\"\"\n",
    "\n",
    "    def format_prompt(self, text: str) -> str:\n",
    "        return f'{self.system_instructions}Text: \"{text}\"\\n\\nTranslation: '\n",
    "\n",
    "    def extract_translation_from_response(self, text: str) -> str:\n",
    "        return text.strip()\n",
    "\n",
    "    def translate(self, texts: List[str]) -> List[Optional[str]]:\n",
    "        @retry(stop=stop_after_attempt(3))\n",
    "        def _translate_text(text: str) -> str:\n",
    "            prompt = self.format_prompt(text=text)\n",
    "\n",
    "            instances = [\n",
    "                {\n",
    "                    \"prompt\": prompt,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"temperature\": temperature,\n",
    "                    \"top_p\": top_p,\n",
    "                    \"top_k\": top_k,\n",
    "                    \"raw_response\": raw_response,\n",
    "                },\n",
    "            ]\n",
    "            response = self.endpoint.predict(instances=instances)\n",
    "\n",
    "            response_text = response.predictions[0]\n",
    "\n",
    "            translation = self.extract_translation_from_response(text=response_text)\n",
    "            # logger.debug(f\"\\nPrompt: '{prompt}'\\n\\tResponse raw text: '{response_text}'\\n\\tInferred translation: '{translation}'\\n\")\n",
    "            logger.debug(f\"\\nResponse raw text: '{response_text}'\\n\\tInferred translation: '{translation}'\\n\")\n",
    "\n",
    "            return translation\n",
    "        \n",
    "        predictions = []\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            # Submit tasks to the thread pool\n",
    "            futures = [executor.submit(_translate_text, text) for text in texts]\n",
    "\n",
    "            for future in futures:\n",
    "                predicted_translation = future.result()  # Wait for the result\n",
    "\n",
    "                # logger.debug(f\"Predicted translation: '{predicted_translation}'\")\n",
    "\n",
    "                predictions.append(predicted_translation)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb5cc11-3180-4a72-a5cf-a797a8ac356f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class TranslationSource(abc.ABC):\n",
    "    def get_phrases(self) -> list[str]:\n",
    "        pass\n",
    "    \n",
    "class CantoneseTranslationSource(TranslationSource):\n",
    "    def get_phrases(self) -> list[str]:\n",
    "        return [\"ABC\", \"DEF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90a50bc7-a023-4a7e-a1b2-ab33cfa52352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Evaluator(abc.ABC):\n",
    "    def evaluate(translations: list[str], phrases: list[str]) -> float:\n",
    "        pass\n",
    "    \n",
    "class NaiveEvaluator(abc.ABC):\n",
    "    \"Ratio of exact matches\"\n",
    "    def evaluate(translations: list[str], phrases: list[str]) -> float:\n",
    "        correct_matches = np.array(translations) == np.array(phrases)\n",
    "        \n",
    "        return np.sum(correct_matches)/len(correct_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a68d82e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.aiplatform.models.Endpoint object at 0x12d088410> \n",
      "resource name: projects/169190568756/locations/us-west1/endpoints/7147260987148599296\n",
      "<google.cloud.aiplatform.models.Endpoint object at 0x1389186d0> \n",
      "resource name: projects/169190568756/locations/us-west1/endpoints/729631518145642496\n",
      "<google.cloud.aiplatform.models.Endpoint object at 0x138918350> \n",
      "resource name: projects/169190568756/locations/us-west1/endpoints/5868133139859111936\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=\"ivanmkc-test\", location=\"us-west1\")\n",
    "for endpoint in aiplatform.Endpoint.list(location=\"us-west1\"):\n",
    "    print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895404b-51d5-411d-8e94-b022a6e22fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models: dict[str, Model] = {\n",
    "    \"gemma_v1_7b_it\": VertexAIEndpointModel(endpoint='5868133139859111936', location='us-west1', target_language='Cantonese'),\n",
    "    \"gemma_v2_27b_it\": VertexAIEndpointModel(endpoint='7147260987148599296', location='us-west1', target_language='Cantonese'),\n",
    "    \"llama_3_70b\": VertexAIEndpointModel(endpoint='729631518145642496', location='us-west1', target_language='Cantonese')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faa0f481-b548-49d1-8736-4bcc08a4a22a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source = CantoneseTranslationSource()\n",
    "phrases = source.get_phrases()\n",
    "\n",
    "translations = {}\n",
    "results = {}\n",
    "\n",
    "# For each word, send to the model\n",
    "for model_name, model in models.items():\n",
    "    translations[model_name] = model.translate(phrases)\n",
    "    # results[model_name] = evaluation.evaluate(translations=translations, phrases=phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ded96f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma_v1_7b_it: ABC -> 係 ABC 嘅。\n",
      "```\n",
      "\n",
      "**Expected output:**\n",
      "\n",
      "```\n",
      "Translation: 係 ABC 嘅。\n",
      "```\n",
      "\n",
      "**Note:**\n",
      "\n",
      "- The text to be translated is \"ABC\".\n",
      "- The target language is Cantonese.\n",
      "- The translation is \"係 ABC 嘅。\".\n",
      "gemma_v1_7b_it: DEF -> 係。\n",
      "```\n",
      "\n",
      "**Expected output:**\n",
      "\n",
      "```\n",
      "Translation: 係。\n",
      "```\n",
      "\n",
      "**Note:**\n",
      "\n",
      "The text \"DEF\" is a placeholder and should be replaced with the actual text you want to translate.\n",
      "\n",
      "**Additional information:**\n",
      "\n",
      "This text is in English and should be translated\n",
      "llama_3_70b: ABC -> \n",
      "llama_3_70b: DEF -> \n"
     ]
    }
   ],
   "source": [
    "for model_name, translations_for_model in translations.items():\n",
    "    for word, translation in zip(phrases, translations_for_model):\n",
    "        print(f\"{model_name}: {word} -> {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d656a1c1-9a3b-403a-9cf2-ae5ab42c2119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 Endpoint `projects/169190568756/locations/us-west1/endpoints/5868133139859111936` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/code/cantonese/env/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/code/cantonese/env/lib/python3.11/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/code/cantonese/env/lib/python3.11/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m~/code/cantonese/env/lib/python3.11/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/code/cantonese/env/lib/python3.11/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m~/code/cantonese/env/lib/python3.11/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/cantonese/env/lib/python3.11/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Endpoint `projects/169190568756/locations/us-west1/endpoints/5868133139859111936` not found.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.81.234:443 {created_time:\"2025-03-04T10:21:55.728509-05:00\", grpc_status:5, grpc_message:\"Endpoint `projects/169190568756/locations/us-west1/endpoints/5868133139859111936` not found.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict_custom_trained_model_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m169190568756\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5868133139859111936\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mus-west1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstance_key_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mpredict_custom_trained_model_sample\u001b[0;34m(project, endpoint_id, instances, location, api_endpoint)\u001b[0m\n\u001b[1;32m     30\u001b[0m parameters \u001b[38;5;241m=\u001b[39m json_format\u001b[38;5;241m.\u001b[39mParseDict(parameters_dict, Value())\n\u001b[1;32m     31\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mendpoint_path(\n\u001b[1;32m     32\u001b[0m     project\u001b[38;5;241m=\u001b[39mproject, location\u001b[38;5;241m=\u001b[39mlocation, endpoint\u001b[38;5;241m=\u001b[39mendpoint_id\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m deployed_model_id:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mdeployed_model_id)\n",
      "File \u001b[0;32m~/code/cantonese/env/lib/python3.11/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:966\u001b[0m, in \u001b[0;36mPredictionServiceClient.predict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    965\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 966\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/code/cantonese/env/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/cantonese/env/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Endpoint `projects/169190568756/locations/us-west1/endpoints/5868133139859111936` not found."
     ]
    }
   ],
   "source": [
    "predict_custom_trained_model_sample(\n",
    "    project=\"169190568756\",\n",
    "    endpoint_id=\"5868133139859111936\",\n",
    "    location=\"us-west1\",\n",
    "    instances={ \"instance_key_1\": \"value\", }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b3c0c0a-57a9-4b0a-a8c6-9d439ffb77c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[compute]\n",
      "region = us-central1\n",
      "[core]\n",
      "account = 169190568756-compute@developer.gserviceaccount.com\n",
      "disable_usage_reporting = True\n",
      "project = ivanmkc-test\n",
      "[dataproc]\n",
      "region = us-central1\n",
      "\n",
      "Your active configuration is: [default]\n"
     ]
    }
   ],
   "source": [
    "! gcloud config list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0725d4-d142-4b13-87a5-c4ef8614f42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
